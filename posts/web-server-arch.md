Webアプリを開発していても、Webサーバーについての詳細な知識が必要になることは少ないです。
依然としてWebアプリはWebサーバーの上で動いてはいますが、クラウドのマネージドサービスで動かすことも多くなった現代でそういった知識が必要になるケースは、経験の少ない僕には想像できません。アプリのボトルネックはもう少し高いレイヤーにあることが多く、パフォーマンス改善のためならそちらを学ぶほうが効率が良いと考えています。

ただ、Webアプリを開発しているとWebサーバーがどのように動いているのか気になると思います。僕は気になります。
特に、Webサーバーがどのように複数のリクエストを処理しているのかがわかりませんでした。

この投稿はWebサーバーの仕組みについて調べ、自分の理解のためにまとめたものです。

## Webサーバーとは

Webサーバーとは、リクエストを受けて何らかのデータをレスポンスとして返すソフトウェアやハードウェアのことです。
データとしてはHTMLページ、画像、CSSスタイルシート、JavaScriptファイル、JSONなどがあり、要求に応じてこれらのデータを返します。

現代のWebサーバーは複数のクライアントからのリクエストを並行して処理する必要があります。
一つのリクエストが処理されるまで他のリクエストをブロックするというように、リクエストを一つずつ処理するだけならイメージはつきやすいと思います。
しかし実際には並行処理が行われるため複雑になります。

Webサーバーのアーキテクチャは並行処理の手法の数だけ存在し、詳細を理解するためにはシステムプログラミングの領域に踏み込む必要があります。
処理を委譲する実行環境でアーキテクチャを分けると、マルチプロセス・マルチスレッド・イベント駆動・ハイブリッドなどがあります。
また、各実行環境でリクエストが処理される方法も異なります。

## ネットワークプログラミングの概要

Webサーバーの仕組みを知るために重要なシステムプログラミングの領域はネットワーク通信です。
Webサーバーはクライアントからネットワークを通してリクエストを受け付けたあと、クライアントからデータを受け取ったり、クライアントにデータを渡したりします。

### 基礎知識

ネットワークプログラミングの概要を知るうえで前提となる基礎的な知識について解説します。

#### システムコール

ここではシステムコールを利用するプログラミングをシステムプログラミングと呼びます。

システムコールは、アプリケーションがOSのカーネルの機能を呼び出すための方法です。
現代のCPUではセキュリティのためにユーザーモードとカーネルモードを区別しています。
カーネルモードは無制限の操作が可能ですが、ユーザーモードには制限があります。
OSは、カーネルモードで動作する処理をシステムコールとして提供し、アプリケーションはシステムコールを通じてカーネルモードでの操作を実行します。

代表的なシステムコールとしては、`open`、`read`、`write`、`close`などがあり、ファイルの操作を行います。
後述するネットワーク通信で使用されるソケットに関連するものとしては、`socket`、`bind`、`listen`、`accept`、`connect`などがあります。
他にネットワーク通信で重要になってくるものだと、`select`や`epoll`(`kqueue`)のようなI/Oイベントの通知のためのシステムコールがあります。

#### ソケット

ネットワーク通信では、ソケットと呼ばれるインターフェースが使用されます。

> [!info]
> ソケットにはUDPで通信するためのUDPソケットや、ネットワークに限らないプロセス間通信を行うためのUNIXドメインソケットなどがありますが、ここでは
> ソケットとだけ言う場合にはTCPソケットを指します。

ソケットは通信におけるエンドポイントを表現したデータモデルのことで、

- ローカルIPアドレス
- ローカルTCPポート
- リモートIPアドレス
- リモートTCPポート

が含まれます。
例えばクライアントとWebサーバーが通信しているとき、Webサーバー側のソケットには、Webサーバー自身の情報がローカルIPアドレス・TCPポートに含まれており、
通信先のクライアントの情報がリモートIPアドレス・TCPポートに含まれています。

ネットワーク通信ではソケットを使用してクライアントからデータを受け取ったり、クライアントにデータを渡すことができます。
具体的には、ソケットを読み取ることでデータを受け取り、ソケットに対して書き込むことでデータを渡すことができます。

#### ファイルディスクリプタ

ソケットは**ファイルディスクリプタ**と呼ばれる整数によって参照されます。

ファイルディスクリプタはUnixにおいてプロセス内のファイルを参照するときに使用される整数のことで、Unixでは様々なリソースがこれによって参照されます。
ファイルやソケットのほか、接続されているキーボードや仮想デバイスであるターミナルなどもあります。
ファイルディスクリプタはプロセス内で一意な整数であり、プロセス間では一意な整数にはなっていません。

このファイルディスクリプタはOS内部に存在するオープンファイル記述と呼ばれるデータで管理されています。
オープンファイル記述の中でプロセスIDとファイルディスクリプタによって、どの情報が参照されるのかが決まります。

Unixのこのような思想は「**Everything is a file**」と呼ばれ、統一したインターフェースであらゆるリソースを扱えるようになります。
例えばファイルの読み込み・書き込みとソケットの読み込み・書き込みを同じシステムコールで行うことができます。

Web開発でもよく見る標準入力、標準出力、標準エラー出力にもファイルディスクリプタが割り当てられており、それぞれ0、1、2になっています。
画面への出力は、標準出力のファイルディスクリプタである1に対してファイル書き込みのシステムコールを実行することで実現できます。

### リクエスト処理のフロー概要

ソケットを使用してWebサーバーとしてリクエストを処理するには、ソケットに関するいくつかのシステムコールを呼ぶ必要があります。
リクエストを処理する流れは以下のようになります。

1. ソケットの作成 (`socket`)
2. ソケットにアドレス割り当て (`bind`)
3. 接続の待機 (`listen`)
4. 接続の受け付け (`accept`)
5. リクエストを処理...
6. ソケットのクローズ (`close`)

Rubyのsocketライブラリを使って書くと、以下のようになります。

```ruby
require 'socket'

server = Socket.new(:INET, :STREAM) # ソケットの作成
addr = Socket.pack_sockaddr_in(4481, '0.0.0.0')
server.bind(addr) # アドレスの割り当て
server.listen(5) # 接続の待機

connection, _ = server.accept # 接続の受け付け
# リクエストを処理...
connection.close
```

`Socket.accept`はリクエストがあるまで後続の処理をブロックし、リクエストが到着するとクライアントと接続されているソケットを作成します。
`accept`はクライアントとWebサーバーでTCPハンドシェイクによってコネクションを確立した時点でブロックを解除します。

この`accept`で作成されたソケットを読み書きしてクライアントとデータをやり取りします。
`accept`によって作成されるソケットには、WebサーバーのIPアドレスとTCPポートがローカル情報として、
クライアントのIPアドレスとTCPポートがリモート情報として含まれているため、クライアントとの通信に使用できます。

また、Rubyのsocketライブラリでは上のようなコードと合わせてリクエスト処理のループを以下のようなコードで簡単に実装できます。

```ruby
require 'socket'

Socket.tcp_server_loop(4481) do | connection |
  # リクエストを処理...
  connection.close
end
```

### ソケットのI/Oモデル

ソケットのI/Oに関するモデルについて解説していきます。

#### ブロッキングI/O

ソケットを読み書きする方法として、**ブロッキングI/O**があります。

**ブロッキングI/O**とは、I/O操作の前に待ちが発生して後続の処理がブロックされるI/Oです。
例えばソケットがノンブロッキングモードではない場合の`read`や`write`が該当します。
ブロッキングI/Oの場合、`read`はデータの読み込み準備が完了するまで処理をブロックし、`write`は書き込み準備が完了するまで処理をブロックします。
`read`はEOFを受け取るか最小バイト数を受け取るまで処理をブロックすることもあります。

ブロッキングI/Oを使用したコードは以下のようになります。

```ruby
require 'socket'

Socket.tcp_server_loop(4481) do | connection |
  request = connection.read
  connection.write request

  connection.close
end
```

#### ノンブロッキングI/O

ソケットを読み書きするもう一つの方法は、**ノンブロッキングI/O**です。

**ノンブロッキングI/O**とは、I/O操作の前に待ちが発生しそうなら即座に関数から返ってくるI/Oです。
例えばソケットがノンブロッキングモードである場合の`read`や`write`が該当します。
ノンブロッキングI/Oの場合、I/O操作の準備ができていないと関数からすぐに返ってきます。

ノンブロッキングI/Oを使用したコードの例は以下のようになります。

```ruby
require 'socket'

Socket.tcp_server_loop(4481) do | connection |
  loop do
    begin
      puts connection.read_nonblock(4096)
    rescue Errno::EAGAIN
      retry
    rescue EOFError
      break
    end
  end

  connection.close
end
```

`read`が準備中の場合にはリトライしていますが、あまり意味がないように見えます。
準備中の場合には`Errno::EAGAIN`が発行されるので、準備が完了するまで`read`を呼び続けています。
`read`がブロックしなくなったとはいえ、結局はループが発生しており、ブロッキングI/Oと変わらないように見えす。

#### I/O多重化

ノンブロッキングI/Oの真価は、**I/O多重化**と一緒に使うことで発揮されます。
詳細は後述するWebサーバーアーキテクチャの[イベント駆動](#イベント駆動)で解説します。

I/O多重化とは、`select`システムコールで複数のファイルディスクリプタを1プロセス1スレッドで管理することを指します。
`select`はI/Oイベントの通知を監視するためのシステムコールですが、効率があまり良くないので現代では効率の良い`epoll`や`kqueue`が使用されます。
インターフェースは異なっていますが、似たようなことを実現するシステムコールなので、ここでは`select`で説明します。

`select`は複数のファイルディスクリプタを監視し、I/O操作の準備が完了しているファイルディスクリプタを返すシステムコールです。
例えばWebサーバーが複数のクライアントと接続している場合、それらのソケットを`select`に渡すと、
I/O操作の準備ができたソケットが返ってきます。
準備ができているソケットがなかったりタイムアウトになるまで`select`は後続の処理をブロックします。

> [!info]
> `select`はファイルディスクリプタを受け取るのですが、通常のディスクファイルは常に準備完了状態とみなされるため、`select`に渡しても意味がありません。
>
> `select`では通常のファイルを渡してもエラーは出ないと思いますが、`epoll`では通常のファイルを渡すと[エラーになる可能性があります。](https://man7.org/linux/man-pages/man2/epoll_ctl.2.html#top_of_page:~:text=EPERM%20%20The%20target%20file%20fd%20does%20not%20support%20epoll.%20%20This%20error%20can%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20occur%20if%20fd%20refers%20to%2C%20for%20example%2C%20a%20regular%20file%20or%20a%0A%20%20%20%20%20%20%20%20%20%20%20%20%20%20directory.)

`select`を使用する`IO.select`を使ったI/O多重化のコードは以下のようになります。

```ruby
connections = [<TCPSocket>, <TCPSocket>, <TCPSocket>]

loop do
  ready = IO.select(connections)

  readable_connections = ready[0]
  readable_connections.each do | conn | 
    data = conn.readpartial(4096)
    process(data)
  end
end
```

ここでは3つのソケットを`IO.select`の第一引数に渡し、読み込み準備が完了したソケットのデータが`IO.select`が返す配列の最初の要素に入っています。
`readpartial`は使用可能なデータをすぐに返すRubyの関数ですが、読み込み準備ができていない場合にはブロックします。
`select`から返って来ているのでI/Oの準備は完了しているためこれを使用しています。

`IO.select`は第一引数に読み込みたいIOオブジェクトの配列、第二引数に書き込みたいIOオブジェクトの配列を渡すことができます。
内部で`select`システムコールが呼ばれ、読み込みと書き込みを監視するファイルディスクリプタの配列が渡されます。

#### 非同期I/O

ソケットを読み書きする方法として、**非同期I/O**もあります。

非同期I/Oは、I/O操作を発行するとすぐに関数から返り、バックグラウンドでI/O操作が実行されます。
Linuxで現在普及しているのはio_uringというもので、Linux独自のシステムコールとして非同期I/Oを実現しています。

ここで言っている非同期I/Oは、あくまでシステムコールレベルでの非同期I/Oです。
プログラミング言語やライブラリは、こういったシステムコールを直接使用せずにアプリケーションレベルの非同期I/Oを実現できます。
アプリケーションレベルの非同期I/Oは、システムコールではなく言語やライブラリが提供する関数でこれを実現する方法といえます。

例えばNode.jsで使われている非同期I/Oのためのライブラリであるlibuvはシステムコールレベルの非同期I/Oを使用していません。
ネットワークI/Oは[非同期I/OではなくノンブロッキングI/O + I/O多重化](https://docs.libuv.org/en/v1.x/design.html#:~:text=all%20(network)%20I/O%20is%20performed%20on%20non%2Dblocking%20sockets%20which%20are%20polled%20using%20the%20best%20mechanism%20available%20on%20the%20given%20platform%3A%20epoll%20on%20Linux%2C%20kqueue%20on%20OSX%20and%20other%20BSDs%2C%20event%20ports%20on%20SunOS%20and%20IOCP%20on%20Windows.)を使用していますし、
I/O多重化が使えないファイルI/Oは[非同期I/Oではなくマルチスレッド + ブロッキングI/O](https://blog.libtorrent.org/2012/10/asynchronous-disk-io/#:~:text=Benefits%20of%20using%20a%20thread%20pool%20with%20blocking%20operations%20instead%20of%20asynchronous%C2%A0disk%20operations)を使っています。

## Webサーバーアーキテクチャ

ここでは、Webサーバーが複数のリクエストを処理している手法で分類されたWebサーバーアーキテクチャについて解説します。
これらのアーキテクチャは[一つのリクエストを処理する方法](#リクエスト処理のフロー概要)がベースになっています。

アーキテクチャの名前は必ずしも一般的なものではありません。

### マルチプロセス

マルチプロセスアーキテクチャは、複数のプロセスでリクエストの並行処理を実現するアーキテクチャです。
1つのプロセスが1つのリクエストを処理し、そのプロセスを複数生成します。

このアーキテクチャは、リクエストを受け付けてからプロセスを生成する方法と、事前に生成したプロセスを使う方法が存在します。
ここでは前者を**オンデマンド型**(造語です)、後者を**prefork型**と呼びます。

**オンデマンド型**はリクエストを受け付けてからプロセスを生成するアーキテクチャです。
処理の流れは以下のようなものが考えられます。

1. サーバーのメインプロセスが接続を受け付ける (`accept`)
2. サーバーのメインプロセスが子プロセス(ワーカープロセス)を`fork`する
3. 子プロセスでリクエストを処理し、メインプロセスは1に戻る

メインプロセスは接続を受け付けるためのソケットを持っており、`accept`したあとに`fork`します。
`fork`では親プロセスのファイルディスクリプタを子プロセスにコピーするため、`accept`で作成されたソケットを子プロセスで操作できます。

オンデマンド型にはシンプルな実装で複数リクエストを並行処理できるというメリットはありますが、リクエスト毎の`fork`は無駄なので事前に生成するアーキテクチャが使われることが多いと思います。
また、大量のリクエストでプロセスの数が膨大な量になってしまい、システムがダウンするという問題が発生する可能性があります。

**prefork型**は事前に子プロセスを生成しておき、子プロセスでリクエストを受け付けるアーキテクチャです。
処理の流れは以下のようなものが考えられます。

1. サーバーのメインプロセスが接続を待機するソケットを作成する
2. サーバーのメインプロセスが指定の数だけ子プロセスを`fork`する
3. 子プロセスが1で作成したソケットで接続を受け付け、処理する

メインプロセスで事前に待機用のソケットを作成して、複数の子プロセスがそのソケットを使って接続を受け付けます。
`fork`するとソケットが親子と兄弟間で共有され、接続があった場合にはどれか一つのプロセスだけが応答します。

prefork型にはリクエストのたびに`fork`のコストを払う必要がないというメリットはありますが、多くのメモリを消費してしまうというデメリットはあります。
また、上の例だと事前に生成したプロセス以上のリクエストがあると性能が落ちてしまいます。

prefork型が使われているWebサーバーソフトウェアとしては、
PHPでよく使われるApache MPM prefork があります。

### マルチスレッド

マルチスレッドアーキテクチャは、複数のスレッドでリクエストの並行処理を実現するアーキテクチャです。
1つのスレッドが1つのリクエストを処理し、そのスレッドを複数生成します。

このアーキテクチャは、リクエストを受け付けてからスレッドを生成する方法と、事前に生成したスレッドを使う方法が存在します。
ここでは前者を**オンデマンド型**(造語です)、後者を**スレッドプール型**と呼びます。

このアーキテクチャはマルチプロセスと似ていますが、プロセスとスレッドにはいくつか違いがあります。
プロセスはスレッドよりも分離性が高く、プロセス間ではメモリを共有しませんが、スレッド間ではメモリを共有します。
一方で、プロセスはメモリを共有せずコピーするので生成のコストが高く、スレッドは共有するので生成のコストが低いです。

**オンデマンド型**はリクエストを受け付けてからにスレッドを生成するアーキテクチャです。
処理の流れは以下のようなものが考えられます。

1. サーバーのメインスレッドが接続を受け付ける (`accept`)
2. サーバーのメインスレッドがスレッドを生成する
3. スレッドでリクエストを処理し、メインスレッドは1に戻る

スレッドはメモリを共有するので、`accept`で生成したソケットをスレッドの中で使用することができます。
プロセスと違いメモリをコピーするわけではないので、ソケットをグローバルな領域に保存しておくとリクエストが分離できないことに注意が必要です。

マルチスレッドのオンデマンド型は、マルチプロセスのオンデマンド型と同じメリット・デメリットがあります。
プロセスと違うのはスレッドのほうが分離性と生成のコストが低いことです。

**スレッドプール型**は事前にスレッドを生成しておき、スレッドでリクエストを受け付けるアーキテクチャです。
処理の流れは以下のようなものが考えられます。

1. サーバーのメインスレッドが接続を待機するソケットを作成する
2. サーバーのメインスレッドが指定の数だけスレッドを生成する
3. スレッドが1で作成したソケットで接続を受け付け、処理する

メインプロセスで事前に待機用のソケットを作成して、複数のスレッドがそのソケットを使って接続を受け付けます。
スレッドはメモリを共有しているので、ソケットを共有することができ、接続があった場合にはどれか一つのスレッドだけが応答します。

こちらもマルチプロセスのprefork型と同じメリット・デメリットがあります。
また、プロセスとスレッドの違いによるメリット・デメリットはオンデマンド型と同じです。

### イベント駆動

イベント駆動アーキテクチャは、シングルスレッドで動作するイベントループでリクエストを並行処理するアーキテクチャです。
1つのスレッドが複数のリクエストを処理します。
一般的には[ノンブロッキングI/O](#ノンブロッキングio)と[I/O多重化](#io多重化)が使用されます。

イベント駆動の処理の流れは以下のようなものが考えられます。以降は`select`を想定しますが、より効率的な`epoll`(`kqueue`)でも同じことが言えます。

1. サーバーは接続を待機するソケットを作成し監視する (`select`)
1. 接続があったら、監視するソケットのリストにそのソケットを追加する
1. サーバーは1と2の接続を監視する
1. アクティブな接続が読み込み可能という通知を受けると、一定サイズだけ読み取り、関連するコールバックを呼び出す
    - 最後まで読み取ったら監視リストから削除し、それ以外の場合は引き続き監視する
1. アクティブな接続が書き込み可能という通知を受けると、一定サイズだけ書き込む
    - 書き込みが終了したら監視リストから削除し、それ以外の場合は引き続き監視する

このアーキテクチャは、イベントループと呼ばれるループの中で「読み込み可能」「書き込み可能」のようなI/Oイベントの通知を`select`で監視して処理します。
読み込みや書き込みなどのI/OにはノンブロッキングI/Oが使われ、一度にすべてのデータが読み書きされるのではなく、一定のサイズで行われます。

このアーキテクチャでは、I/O多重化によって以下のソケットを1つのスレッドで管理します。

- クライアントからの接続を待機する1つのソケット
- 読み込みを監視したい複数のソケット
- 書き込みを監視したい複数のソケット

接続を待機するソケットはサーバーの起動時に生成して監視し、リクエストを受け付けて生成されたソケットも合わせて監視します。
起動時に生成したソケットで`accept`を行い、接続が確立されて`accept`で作成されたソケットを監視リストに追加していきます。

4の読み込みにはクライアントからのリクエストデータの読み込みが含まれ、「関連するコールバック」にリクエストの処理が含まれています。
このコールバックの中ですべてのリクエストデータが揃ったときに何らかの処理を実行し、レスポンスに書き込みます。
データを最後(EOF)まで読み込めなかった場合には、次の通知で読み込みを再開します。

5の書き込みにはクライアントへのレスポンスデータの書き込みが含まれています。
データを最後まで書き込めなかった場合には、次の通知で書き込みを再開します。

イベント駆動のメリットは、プロセスやスレッドの生成のコストや生成の上限の影響を受けないことです。
マルチプロセス/マルチスレッドのオンデマンド型ではプロセス/スレッドの生成コストや大量の生成でパフォーマンスが落ちてしまう問題がありましたが、このアーキテクチャでは1プロセス1スレッドなので影響を受けません。
preforkやスレッドプールの場合には事前に生成する数を決めなければいけないという問題がありましたが、こちらも問題にはなりません。
上記のような問題はC10K問題と呼ばれることもあり、イベント駆動はそれを解決すると言えます。

イベント駆動のデメリットは、リクエストの処理中にブロッキングするコードを書くとスレッドごとブロックされてしまうことです。
例えば上記の処理の流れの4にあるコールバックの中で無限ループをするようなコードを書くと、リクエストを受け付けられなくなります。
これはマルチプロセス/マルチスレッドのアーキテクチャでは発生しない問題です。

コンピュータにおける処理は、性能が制限される要因によって**CPUバウンド**な処理、**I/Oバウンド**な処理に分類することができます。
CPUによって性能が制限される処理がCPUバウンドな処理で、データの暗号化や画像処理などの処理が該当します。
I/Oによって性能が制限される処理がI/Oバウンドな処理で、データベースの操作や外部APIの呼び出しなどの処理が該当します。

イベント駆動は、I/Oバウンドな処理が多いケースで性能を発揮することができますが、CPUバウンドな処理が多いケースでは性能が発揮できないことがあると言えます。
ただ、CPUバウンドな処理を外部のAPIにオフロードして、I/Oバウンドな処理にすることはできるかもしれません。

また、イベント駆動はCPUの性能を限界まで引き出すことが難しいというデメリットもあります。
このアーキテクチャは1スレッドで動作するため、CPUのコア数が増えても1スレッドを処理しているコア以外は無駄になってしまいます。

イベント駆動はNode.js (libuv) で使われています。

### ハイブリッド

上記のアーキテクチャを部分的に組み合わせたアーキテクチャをハイブリットアーキテクチャと呼びます。
ここでは**マルチプロセス/マルチスレッド → イベント駆動**を紹介します。

このアーキテクチャは、preforkやスレッドプールで事前にプロセス/スレッドを生成しておき、
それぞれのプロセス/スレッドの中でイベント駆動を使用してリクエストを並行処理するものです。

これはCPUの性能を引き出すことが難しいというイベント駆動のデメリットを解消しています。
マルチプロセス/マルチスレッドのなかでイベント駆動が使用されるため、一つのサーバーで複数のプロセス/スレッドが使用され、マルチコアの恩恵を受けることができます。

また、複数のイベントループが動いているので、イベント駆動のみと比べるとCPUバウンドな処理が多くなっても性能が落ちにくいと思います。
一つのイベントループがブロックされても、他のイベントループで接続を受け付けることができます。

「マルチプロセス → イベント駆動」に近いとしてはNginxがあります。
Nginxは複数のプロセスが1つのスレッドだけを持っており、そのスレッドがイベント駆動でリクエストを並行処理します。

他にも、「マルチプロセス → イベント駆動」に近い例としてApache MPM eventがあります。
Apach MPM eventは各プロセス内の一つのリスナースレッドで接続を待ち受け、複数のワーカースレッドにリクエストを委譲します。
厳密に言うとイベント駆動なのは接続を待ち受けているリスナースレッドのみで、ワーカースレッドは異なります。
ワーカースレッド内ではブロッキングI/Oも使用され、ワーカースレッドがブロックされることもあります。
ワーカースレッドは複数存在しますが、プロセス内でイベント駆動なのは1スレッドだけなのでマルチスレッドではなく「マルチプロセス → イベント駆動」に分類しました。

### グリーンスレッド

グリーンスレッドアーキテクチャは、ユーザーランドで管理される軽量なスレッドであるグリーンスレッドでリクエストを並行処理するアーキテクチャです。
1つのグリーンスレッドで1つのリクエストを処理し、グリーンスレッドを複数作成します。

一般的に現代のグリーンスレッドはM:Nモデルと呼ばれるものになっています。
これはM個のグリーンスレッドをN個のネイティブスレッドで実行するというモデルです。
1つのネイティブスレッドで複数のグリーンスレッドを実行するよりも、CPUのマルチコアを活かすことができます。

グリーンスレッドはスレッドよりも軽量で、生成や切り替えのコストが低いです。
そのため、プロセスやスレッドと比べて少ないリソースで大量に生成することができ、C10K問題の解決策として使うことができます。

このアーキテクチャが使われているものとしては、RustのtokioやGoのgoroutineなどがあります。

## WebサーバーとWebアプリのやり取り

Webサーバーのアーキテクチャについて紹介しましたが、WebサービスではWebサーバーとWebアプリが連携する必要があります。
この連携方法は複数あり、様々な技術が使われてきました。
CGIやFastCGI、組み込みモジュール、言語ごとのインターフェースなどがあります。
また、標準ライブラリだけで高性能なWebサーバーを実装できる言語もあり、そういった言語ではWebサーバーとWebアプリが一体化しているケースもあります。

ここでは、WebサーバーとWebアプリの連携方法を簡単に見ていきます。

**CGI**(Common Gateway Interface)は、標準入出力を使用してWebアプリと通信する方法です。
リクエストに応じてCGIプログラム(Webアプリ)を起動し、標準入力や環境変数でプログラムにデータを渡して、標準出力に出力されたデータをクライアントに送信します。
CGIプログラムのファイルにはスクリプトを読み込むインタプリタを指定するShebang(シェバン)が含まれることが多く、これを使ってファイルを実行します。
PHPであれば`php script.php`をWebサーバーが実行するようなイメージです。
CGIは過去に使われていた仕組みであり、リクエストごとにプロセスが生成されるためオーバーヘッドが大きいです。

**FastCGI**は、プロセスを事前にプールして再利用するCGIです。
リクエストを受け取ると待機しているプロセスでリクエストを処理し、ソケットを使用してWebサーバーとデータをやり取りします。
FastCGIの実装としてはPHPのFPMがあり、Nginxではこのphp-fpmを使用することが多いです。
このとき、FastCGIクライアントであるNginxがリクエストを受け付けて、FastCGIサーバーであるphp-fpmがリクエストを取得して処理するという流れになります。
PHPだと後述する組み込みモジュールがよく使われていましたが、これを非推奨にしているOSも出てきて、最近だとFastCGIが使われることも多くなってきました。

> [!info]
> Nginxはイベント駆動でFastCGIはプロセスのリクエストを処理なので、組み合わせることができるのかと疑問でしたが、
おそらくリクエストを受け付ける部分だけがイベント駆動で実行され、FastCGIサーバーにリクエストを渡して以降はイベント駆動ではなくなるというようなことだと思います。
>先述した[ハイブリッドアーキテクチャ](#ハイブリッド)のApache eventのような挙動になっているのだと想像しています。

**組み込みモジュール**は、言語をApache HTTP Serverに結合するためのモジュールです。
リクエストを受け取るとWebサーバーであるApacheのプロセス内で直接Webアプリを実行してリクエストを処理します。
このモジュールは言語ごとに実装されており、mod_phpやmod_python、mod_rubyなどがあります。
ただ、PHP以外の言語ではApacheではなく、後述するWebアプリと同じ言語で実装されたWebサーバーを使うため、mod_php以外はあまり使われていないと思います。

**言語ごとのインターフェース**は、WebサーバーとWebアプリを連携するための言語ごとのインターフェースのことです。
PythonのWSGIやASGI、RubyのRackなどがあり、対応したWebサーバーとWebアプリを連携させることができます。
これらのインターフェースは、複数のWebサーバーと複数のWebアプリフレームワークで互換性を高めるために作られました。
大量のWebフレームワークが乱立していた時代に、複数のWebサーバーに対応させるのが開発者の負担になっていたという背景があったみたいです。

また、最適化のためにWebアプリと同じ言語で作られたWebサーバーが使われることがあります。
特にPythonやRubyが有名で、Pythonだと上述するWSGIを実装しているGunicornやASGIを実装しているUvicorn、RubyだとRackを使用しているPumaなどがあります。

**WebサーバーとWebアプリが一体化**しているケースもあります。
これは、標準ライブラリだけで高性能なWebサーバーを実装できる言語でよくみられます。
例えばGoやNode.jsは標準ライブラリだけで高性能なWebサーバーを実装できるので、専用のWebサーバーソフトウェアが必要になることが少ないです。
Rustは標準ライブラリにはありませんが、非同期ランタイムライブラリを使うことで高性能なWebサーバーを実装することはできます。

## リバースプロキシ/ロードバランサ

Webサービスの規模が大きくなってくると、クライアントとWebサーバーの間にリバースプロキシやロードバランサが必要になるかもしれません。
Webサーバーが直接リクエストを受け付けていると、大量のリクエストを捌ききれない可能性があります。

**リバースプロキシ**は、クライアントとWebサーバーの間に入って、さまざまな前後処理を行うサービスです。
クライアントからリクエストを受け取ってWebサーバーに転送するサービスというのが狭義の定義だと思いますが、
リバースプロキシといったときには、さまざまな前後処理を想定していることが多いです。
リバースプロキシはWebサーバーの前段に配置して制御可能なポイントを増やし、Webサービス全体のリソースを最適化するために使用されるます。

リバースプロキシが行う処理の例としては、URLのリライトや静的ファイルの配信が挙げられます。
URLのリライトによって、システムを変更することなく外から見えるURLを柔軟に変更できます。
また、静的ファイルをリバースプロキシから配信することで、Webサーバーのリソースを動的コンテンツ処理に集中させることも可能です。

リバースプロキシは、静的ファイル配信の用途での必要性は低下したものの、システムの制御ポイントを増やすというメリットはあります。
最近は静的ファイル配信にはCDNが広く利用されるようになり、この用途でのリバースプロキシの必要性は低下しています。
しかし、Webサーバーの前段にリバースプロキシを配置することで、システムの制御ポイントを増やすことができます。
これにより、問題が発生した際の対応が容易になり、Webアプリ自体を変更せずに問題を解決できる可能性が高まります。

**ロードバランサ**は、複数のWebサーバーにリクエストを振り分けて負荷を分散させるサービスです。
リバースプロキシがロードバランサとして機能する場合もあります。
負荷が増加してリクエストを捌くのが難しくなった場合でも、ロードバランサを使用することで裏にあるWebサーバーを増やし、システムをスケールさせることが可能になります。
それぞれのWebサーバーにSSL証明書を発行する必要をなくすために、ロードバランサでSSLを終端させる事もできます。

仮想化技術の発展によってWebサーバーを水平に並べるケースが増えたため、ロードバランサはより重要なコンポーネントになっていると感じています。
水平スケーリングが増えた理由としては、仮想化技術によってWebサーバーの台数を柔軟に調整できるようになったことが挙げられます。
また、1台の物理サーバー上で複数のWebサーバーを動かせるようになり、コストが低くなったというのもあると思います。

水平に並べるケースが増えた結果、Webサーバー1台の性能が以前よりも重要ではなくなっています。
そのため、Webサーバーアーキテクチャでも少し触れたC10K問題などは、当時よりも影響が少なくなっていると考えられます。
Webサーバー1台でリクエストが捌けないのであればWebサーバーを増やせば良く、それを昔よりも容易に行うことができます。

## さいごに

Webサーバーについてまとめました。

## 参考資料

- [2015年Webサーバアーキテクチャ序論](https://blog.yuuk.io/entry/2015-webserver-architecture)
- [Webサーバーアーキテクチャ進化論2023](https://blog.ojisan.io/server-architecture-2023)
- [WebエンジニアとWeb技術とシステムの話 (sadnessOjisanのWebサーバーアーキテクチャ進化論2023を読んだ感想)](https://blog.inductor.me/entry/2023/04/03/153149)
- [なるほどTCPソケット(Working with TCP sockets)](https://www.snoozer05.org/naruhotcp)
- [Webサーバにおけるソケット周りの知識](https://christina04.hatenablog.com/entry/socket-base)
- [Non-Blocking I/O, I/O Multiplexing, Asynchronous I/Oの区別](https://christina04.hatenablog.com/entry/2017/07/05/005944)
- [I/O Multiplexing（I/O多重化）](https://christina04.hatenablog.com/entry/io-multiplexing)
- [ノンブロッキングI/Oと非同期I/Oの違いを理解する](https://blog.takanabe.tokyo/2015/03/%E3%83%8E%E3%83%B3%E3%83%96%E3%83%AD%E3%83%83%E3%82%AD%E3%83%B3%E3%82%B0i/o%E3%81%A8%E9%9D%9E%E5%90%8C%E6%9C%9Fi/o%E3%81%AE%E9%81%95%E3%81%84%E3%82%92%E7%90%86%E8%A7%A3%E3%81%99%E3%82%8B/)
- [「同期I/O」と「非同期I/O」の定義、とか](https://hirose31.hatenablog.jp/entry/20070815/1187149760)
- [Linuxにおける非同期IOの実装について](https://qiita.com/tmsn/items/0b9e5f84f9fbc56c1c82)
- [epoll_ctl(2) — Linux manual page](https://man7.org/linux/man-pages/man2/epoll_ctl.2.html)
- [libuv - Design overview](https://docs.libuv.org/en/v1.x/design.html)
- [process-book - ファイルディスクリプタ](https://shinpeim.github.io/process-book/004.md/)
- [言語のスレッド実装の雑な話(Green threadからGoのgoroutineまで)](https://zenn.dev/tetsu_koba/articles/e197c25899cd85)
- [The Architecture of Open Source Applications (Volume 2) nginx](https://aosabook.org/en/v2/nginx.html)
- [Apache2.4そろそろリリース…かもしれないので非同期I/Oのevent mpmの紹介](https://dev.ariel-networks.com/wp/archives/1290/)
- [Apacheコミッターが見た、Apache vs nginx](https://openstandia.jp/pdf/140228_osc_seminar_ssof8.pdf)
- [Apacheのevent MPMのパフォーマンスチューニング方法](https://qiita.com/rryu/items/5e02ea60e36d7fd956b8)
- [Apache Tutorial: CGI による動的コンテンツ](https://httpd.apache.org/docs/current/howto/cgi.html)
- [FastCGI.com Archives](https://fastcgi-archives.github.io/)
- [FastCGI Process Manager (FPM) ¶](https://www.php.net/manual/ja/install.fpm.php)
- [あなたのサイトの PHPは、CGI方式ですか？ Module方式ですか？](https://www.fumi.org/neta/201205sv.html)
- [WSGI/Rack/PSGIの登場の背景](https://shin.hateblo.jp/entry/2013/10/22/000030)
- [はてなで大規模サービスのインフラを学んだ](https://blog.yuuk.io/entry/large-scale-infrastructure)
- [Reverse Proxy がなぜ必要か](https://naoya-2.hatenadiary.org/entry/20140826/1409024573)
- [Reverse Proxyがなぜ必要か、勝手に補遺](https://tagomoris.hatenablog.com/entry/2014/08/26/130559)
- [Re: NginxとApacheって何が違うの？？](https://blog.inductor.me/entry/2022/05/31/150707)
